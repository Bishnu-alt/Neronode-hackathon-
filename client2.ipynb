{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b58440ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: mysql-connector-python in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49342653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "# import pickle\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# conn_config = {\n",
    "#     'host': '192.168.91.185',\n",
    "#     'user': 'clientUser',\n",
    "#     'password': 'ronaldo7',\n",
    "#     'database': 'fl_database'\n",
    "# }\n",
    "# conn = mysql.connector.connect(**conn_config)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "\n",
    "# cursor.execute(\"SELECT model_blob FROM central_models WHERE model_id = %s AND version = %s\", (1, 1))\n",
    "# result = cursor.fetchone()\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "\n",
    "# if result is None:\n",
    "#     raise Exception(\"Model not found in database.\")\n",
    "# model_blob = result[0]\n",
    "# model_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46239bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if isinstance(model_blob, str):\n",
    "#     model_blob = model_blob.encode('latin1')  # Or 'utf-8' if needed\n",
    "# model = pickle.loads(model_blob)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d6c0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "# import numpy as np\n",
    "# data = pd.read_csv('client_3_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98adb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d938582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data.drop('Diabetes_binary', axis=1)\n",
    "# y = data['Diabetes_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90d62690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db1e92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aae44336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train)\n",
    "# y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af377c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "# test_cm = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "490bfadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training Confusion Matrix:\")\n",
    "# print(train_cm)\n",
    "# print(\"\\nTest Confusion Matrix:\")\n",
    "# print(test_cm)\n",
    "\n",
    "# # Evaluate the model\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "# print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "# print(\"\\nTest Classification Report:\")\n",
    "# print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "684b37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"\\nTrain Classification Report:\")\n",
    "# print(classification_report(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a8fb0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss\n",
    "\n",
    "# # Predict probabilities instead of classes\n",
    "# y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# # Calculate log loss\n",
    "# loss = log_loss(y_test, y_prob)\n",
    "# print(\"Log Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97e9e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "# import pickle\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Sample values (replace with dynamic evaluation if needed)\n",
    "# accuracy = 0.72\n",
    "# loss = loss\n",
    "\n",
    "# # Model serialization\n",
    "# model_blob = pickle.dumps(model)\n",
    "\n",
    "# # Classification report as a dictionary\n",
    "# report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "# # Extract metrics\n",
    "# macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "# recall_minority = report[\"1.0\"][\"recall\"]\n",
    "# f1_minority = report[\"1.0\"][\"f1-score\"]\n",
    "# f1_majority = report[\"0.0\"][\"f1-score\"]\n",
    "\n",
    "\n",
    "# fit_status = \"good\"\n",
    "\n",
    "# # DB Insert Details\n",
    "# model_id = 1\n",
    "# client_id = \"3\"\n",
    "# round_num = 1\n",
    "\n",
    "# # DB Connection\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"192.168.1.11\",\n",
    "#     user=\"clientUser\",\n",
    "#     password=\"ronaldo7\",\n",
    "#     database=\"fl_database\"\n",
    "# )\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Updated insert query\n",
    "# insert_query = \"\"\"\n",
    "# INSERT INTO client_updates \n",
    "# (model_id, client_id, model_blob, accuracy, loss, round_num, macro_f1, recall_minority, f1_minority, f1_majority, fit_status)\n",
    "# VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute Insert\n",
    "# cursor.execute(insert_query, (\n",
    "#     model_id, client_id, model_blob, accuracy, loss, round_num,\n",
    "#     macro_f1, recall_minority, f1_minority, f1_majority, fit_status\n",
    "# ))\n",
    "# conn.commit()\n",
    "\n",
    "# print(\" Model update inserted successfully with classification metrics.\")\n",
    "\n",
    "# cursor.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14fb71fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! pip install optuna \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0b92469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a6bf0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('client_2_binary.csv')\n",
    "X = data.drop(\"Diabetes_binary\", axis=1)\n",
    "y = data[\"Diabetes_binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b816cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290613c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Create the Logistic Regression model\n",
    "# model = LogisticRegression(random_state=42, max_iter=200)\n",
    "\n",
    "# # Fit the model on training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Now you can predict on test data, for example:\n",
    "# y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# def objective(trial):\n",
    "#     penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "#     solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs', 'newton-cg'])\n",
    "    \n",
    "#     if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "#         raise optuna.TrialPruned()\n",
    "#     if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs', 'newton-cg']:\n",
    "#         raise optuna.TrialPruned()\n",
    "    \n",
    "#     C = trial.suggest_loguniform('C', 1e-3, 10)\n",
    "#     max_iter = trial.suggest_int('max_iter', 100, 300)\n",
    "#     class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "    \n",
    "#     model = LogisticRegression(\n",
    "#         penalty=penalty,\n",
    "#         C=C,\n",
    "#         solver=solver,\n",
    "#         max_iter=max_iter,\n",
    "#         class_weight=class_weight,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predict probabilities on test set (for all classes)\n",
    "#     y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "#     # Calculate log loss (lower is better)\n",
    "#     loss = log_loss(y_test, y_proba)\n",
    "    \n",
    "#     # Return negative loss because Optuna maximizes the objective\n",
    "#     return -loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95d99d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, f1_score, classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Identify the minority class from the training data\n",
    "from collections import Counter\n",
    "minority_class = min(Counter(y_train), key=Counter(y_train).get)\n",
    "\n",
    "def objective(trial):\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs', 'newton-cg'])\n",
    "\n",
    "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs', 'newton-cg']:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    C = trial.suggest_float('C', 1e-3, 10, log=True)\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 300)\n",
    "    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Step 2: Compute recall and f1 for minority class only\n",
    "    recall_min = recall_score(y_test, y_pred, pos_label=minority_class)\n",
    "    f1_min = f1_score(y_test, y_pred, pos_label=minority_class)\n",
    "\n",
    "    # Step 3: Return a combination (you can tweak this)\n",
    "    return recall_min + 0.5 * f1_min  # prioritizing recall more, but not ignoring F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4cb8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:42:27,680] A new study created in memory with name: no-name-3a9fe788-c0fb-4740-8740-20ac850f2fa3\n",
      "[I 2025-07-26 00:42:27,683] Trial 0 pruned. \n",
      "[I 2025-07-26 00:42:27,683] Trial 1 pruned. \n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:28,458] Trial 2 finished with value: 0.14606767904012 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.003251334907503341, 'max_iter': 126, 'class_weight': None}. Best is trial 2 with value: 0.14606767904012.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:31,972] Trial 3 finished with value: 0.9951865890916588 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.0031023133969122515, 'max_iter': 127, 'class_weight': 'balanced'}. Best is trial 3 with value: 0.9951865890916588.\n",
      "[I 2025-07-26 00:42:35,368] Trial 4 finished with value: 0.2778589520715505 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.03215402071748648, 'max_iter': 225, 'class_weight': None}. Best is trial 3 with value: 0.9951865890916588.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:37,241] Trial 5 finished with value: 0.27975105731870853 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.26640029983074215, 'max_iter': 151, 'class_weight': None}. Best is trial 3 with value: 0.9951865890916588.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:38,687] Trial 6 finished with value: 0.2632857839672696 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.04117914634317041, 'max_iter': 299, 'class_weight': None}. Best is trial 3 with value: 0.9951865890916588.\n",
      "[I 2025-07-26 00:42:38,687] Trial 7 pruned. \n",
      "[I 2025-07-26 00:42:38,687] Trial 8 pruned. \n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:39,291] Trial 9 finished with value: 0.9995292214804224 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.522345666986805, 'max_iter': 116, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9995292214804224.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:44,737] Trial 10 finished with value: 0.9972234666423688 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 9.98202416892764, 'max_iter': 199, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9995292214804224.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:49,921] Trial 11 finished with value: 0.9972590932161449 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 7.857406771237494, 'max_iter': 200, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9995292214804224.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:42:54,503] Trial 12 finished with value: 0.9977685260837498 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 7.5302916564091475, 'max_iter': 188, 'class_weight': 'balanced'}. Best is trial 9 with value: 0.9995292214804224.\n",
      "[I 2025-07-26 00:42:56,053] Trial 13 finished with value: 0.9995651765894924 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.0307699440204325, 'max_iter': 168, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.9995651765894924.\n",
      "[I 2025-07-26 00:42:57,619] Trial 14 finished with value: 0.9995651765894924 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.6194715077403892, 'max_iter': 158, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.9995651765894924.\n",
      "[I 2025-07-26 00:42:59,181] Trial 15 finished with value: 0.9995651765894924 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.8524063822964494, 'max_iter': 164, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.9995651765894924.\n",
      "[I 2025-07-26 00:43:00,756] Trial 16 finished with value: 0.9995651765894924 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.013680596254632, 'max_iter': 238, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.9995651765894924.\n",
      "[I 2025-07-26 00:43:02,354] Trial 17 finished with value: 0.9995651765894924 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.8463150110363908, 'max_iter': 163, 'class_weight': 'balanced'}. Best is trial 13 with value: 0.9995651765894924.\n",
      "[I 2025-07-26 00:43:03,898] Trial 18 finished with value: 1.0002170240092791 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.14746990227614978, 'max_iter': 100, 'class_weight': 'balanced'}. Best is trial 18 with value: 1.0002170240092791.\n",
      "[I 2025-07-26 00:43:05,457] Trial 19 finished with value: 1.0009767656100101 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.10326766376819418, 'max_iter': 109, 'class_weight': 'balanced'}. Best is trial 19 with value: 1.0009767656100101.\n",
      "[I 2025-07-26 00:43:07,035] Trial 20 finished with value: 1.0009767656100101 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.08896769229505105, 'max_iter': 100, 'class_weight': 'balanced'}. Best is trial 19 with value: 1.0009767656100101.\n",
      "[I 2025-07-26 00:43:08,766] Trial 21 finished with value: 1.0010127727902014 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.08552312455464674, 'max_iter': 104, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:10,246] Trial 22 finished with value: 1.0001451197410194 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.04241539201998456, 'max_iter': 100, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:11,833] Trial 23 finished with value: 0.998985210814416 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.011813087335043639, 'max_iter': 140, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:12,307] Trial 24 finished with value: 1.0009767656100101 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.09425519135966788, 'max_iter': 115, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:12,851] Trial 25 finished with value: 0.9990211979316539 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.011098506113405545, 'max_iter': 135, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:13,655] Trial 26 finished with value: 0.27964436382624946 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.10913574068544493, 'max_iter': 102, 'class_weight': None}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:14,210] Trial 27 finished with value: 1.000360971827674 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.013009479191747712, 'max_iter': 293, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:14,752] Trial 28 finished with value: 0.9996011433044724 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.23930916094047344, 'max_iter': 117, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:15,476] Trial 29 finished with value: 0.9977171971150665 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.05929854742817282, 'max_iter': 141, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:16,270] Trial 30 finished with value: 0.2733852737240154 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.020735230647999144, 'max_iter': 255, 'class_weight': None}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:16,794] Trial 31 finished with value: 1.0009767656100101 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.08708954915981527, 'max_iter': 113, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:17,314] Trial 32 finished with value: 0.9995651765894924 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.21431755337433783, 'max_iter': 114, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:17,859] Trial 33 finished with value: 1.0009767656100101 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.0826757640798166, 'max_iter': 124, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:17,862] Trial 34 pruned. \n",
      "[I 2025-07-26 00:43:18,433] Trial 35 finished with value: 0.9926489675215937 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.0013668565360072922, 'max_iter': 131, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:18,988] Trial 36 finished with value: 0.9998938196514096 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.35495665582938873, 'max_iter': 110, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:23,242] Trial 37 finished with value: 0.9977685260837498 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.14068829767310442, 'max_iter': 145, 'class_weight': 'balanced'}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:23,961] Trial 38 finished with value: 0.25069332701125363 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.006215875268124792, 'max_iter': 127, 'class_weight': None}. Best is trial 21 with value: 1.0010127727902014.\n",
      "[I 2025-07-26 00:43:23,964] Trial 39 pruned. \n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:24,464] Trial 40 finished with value: 1.0030883158835915 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.027815504293823668, 'max_iter': 123, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:24,996] Trial 41 finished with value: 1.0023656297770471 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.030263101668160503, 'max_iter': 121, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:25,533] Trial 42 finished with value: 1.001358544970611 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.02323877548366756, 'max_iter': 180, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:26,061] Trial 43 finished with value: 1.0023300143883234 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.030753234804811916, 'max_iter': 126, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:26,547] Trial 44 finished with value: 0.24516612079641464 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.017607203044903208, 'max_iter': 177, 'class_weight': None}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:28,496] Trial 45 finished with value: 0.997946616364372 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.027640283373921142, 'max_iter': 151, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:28,879] Trial 46 finished with value: 0.9896816748352885 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.005359934590850742, 'max_iter': 229, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:29,417] Trial 47 finished with value: 0.9984559372274998 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.04569127514390552, 'max_iter': 182, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:29,898] Trial 48 finished with value: 0.2468465026777313 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.027553018667226183, 'max_iter': 210, 'class_weight': None}. Best is trial 40 with value: 1.0030883158835915.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:43:30,287] Trial 49 finished with value: 0.9975168840946674 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.006975142050378992, 'max_iter': 126, 'class_weight': 'balanced'}. Best is trial 40 with value: 1.0030883158835915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.027815504293823668, 'max_iter': 123, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de062261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7269000315357931\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.72      0.82     10906\n",
      "         1.0       0.31      0.78      0.44      1778\n",
      "\n",
      "    accuracy                           0.73     12684\n",
      "   macro avg       0.63      0.75      0.63     12684\n",
      "weighted avg       0.86      0.73      0.77     12684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Retrain with best model\n",
    "best_model = LogisticRegression(**best_params, random_state=42, n_jobs=-1)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Final predictions and evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58ca7384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model update inserted successfully with classification metrics.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Sample values (replace with dynamic evaluation if needed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "\n",
    "# Model serialization\n",
    "model_blob = pickle.dumps(best_model)\n",
    "\n",
    "# Classification report as a dictionary\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract metrics\n",
    "macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "recall_minority = report[\"1.0\"][\"recall\"]\n",
    "f1_minority = report[\"1.0\"][\"f1-score\"]\n",
    "f1_majority = report[\"0.0\"][\"f1-score\"]\n",
    "\n",
    "\n",
    "fit_status = \"good\"\n",
    "\n",
    "# DB Insert Details\n",
    "model_id = 1\n",
    "client_id = \"2\"\n",
    "round_num = 2\n",
    "\n",
    "# DB Connection\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"centralAuth\",\n",
    "    password=\"messi10\",\n",
    "    database=\"fl_database\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Updated insert query\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO client_updates \n",
    "(model_id, client_id, model_blob, accuracy, loss, round_num, macro_f1, recall_minority, f1_minority, f1_majority, fit_status)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Execute Insert\n",
    "cursor.execute(insert_query, (\n",
    "    model_id, client_id, model_blob, accuracy, loss, round_num,\n",
    "    macro_f1, recall_minority, f1_minority, f1_majority, fit_status\n",
    "))\n",
    "conn.commit()\n",
    "\n",
    "print(\" Model update inserted successfully with classification metrics.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
