{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58440ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: mysql-connector-python in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (9.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49342653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "# import pickle\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# conn_config = {\n",
    "#     'host': '192.168.91.185',\n",
    "#     'user': 'clientUser',\n",
    "#     'password': 'ronaldo7',\n",
    "#     'database': 'fl_database'\n",
    "# }\n",
    "# conn = mysql.connector.connect(**conn_config)\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "\n",
    "# cursor.execute(\"SELECT model_blob FROM central_models WHERE model_id = %s AND version = %s\", (1, 1))\n",
    "# result = cursor.fetchone()\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "\n",
    "# if result is None:\n",
    "#     raise Exception(\"Model not found in database.\")\n",
    "# model_blob = result[0]\n",
    "# model_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46239bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if isinstance(model_blob, str):\n",
    "#     model_blob = model_blob.encode('latin1')  # Or 'utf-8' if needed\n",
    "# model = pickle.loads(model_blob)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d6c0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "# import numpy as np\n",
    "# data = pd.read_csv('client_3_binary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98adb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d938582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data.drop('Diabetes_binary', axis=1)\n",
    "# y = data['Diabetes_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d62690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1e92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae44336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = model.predict(X_train)\n",
    "# y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af377c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "# test_cm = confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490bfadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Training Confusion Matrix:\")\n",
    "# print(train_cm)\n",
    "# print(\"\\nTest Confusion Matrix:\")\n",
    "# print(test_cm)\n",
    "\n",
    "# # Evaluate the model\n",
    "# train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "# test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "# print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "# print(\"\\nTest Classification Report:\")\n",
    "# print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "684b37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"\\nTrain Classification Report:\")\n",
    "# print(classification_report(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a8fb0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss\n",
    "\n",
    "# # Predict probabilities instead of classes\n",
    "# y_prob = model.predict_proba(X_test)\n",
    "\n",
    "# # Calculate log loss\n",
    "# loss = log_loss(y_test, y_prob)\n",
    "# print(\"Log Loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e9e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "# import pickle\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Sample values (replace with dynamic evaluation if needed)\n",
    "# accuracy = 0.72\n",
    "# loss = loss\n",
    "\n",
    "# # Model serialization\n",
    "# model_blob = pickle.dumps(model)\n",
    "\n",
    "# # Classification report as a dictionary\n",
    "# report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "\n",
    "# # Extract metrics\n",
    "# macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "# recall_minority = report[\"1.0\"][\"recall\"]\n",
    "# f1_minority = report[\"1.0\"][\"f1-score\"]\n",
    "# f1_majority = report[\"0.0\"][\"f1-score\"]\n",
    "\n",
    "\n",
    "# fit_status = \"good\"\n",
    "\n",
    "# # DB Insert Details\n",
    "# model_id = 1\n",
    "# client_id = \"3\"\n",
    "# round_num = 1\n",
    "\n",
    "# # DB Connection\n",
    "# conn = mysql.connector.connect(\n",
    "#     host=\"192.168.1.11\",\n",
    "#     user=\"clientUser\",\n",
    "#     password=\"ronaldo7\",\n",
    "#     database=\"fl_database\"\n",
    "# )\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# # Updated insert query\n",
    "# insert_query = \"\"\"\n",
    "# INSERT INTO client_updates \n",
    "# (model_id, client_id, model_blob, accuracy, loss, round_num, macro_f1, recall_minority, f1_minority, f1_majority, fit_status)\n",
    "# VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "# \"\"\"\n",
    "\n",
    "# # Execute Insert\n",
    "# cursor.execute(insert_query, (\n",
    "#     model_id, client_id, model_blob, accuracy, loss, round_num,\n",
    "#     macro_f1, recall_minority, f1_minority, f1_majority, fit_status\n",
    "# ))\n",
    "# conn.commit()\n",
    "\n",
    "# print(\" Model update inserted successfully with classification metrics.\")\n",
    "\n",
    "# cursor.close()\n",
    "# conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14fb71fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! pip install optuna \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0b92469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6bf0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('client_1_binary.csv')\n",
    "X = data.drop(\"Diabetes_binary\", axis=1)\n",
    "y = data[\"Diabetes_binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b816cf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "290613c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Create the Logistic Regression model\n",
    "# model = LogisticRegression(random_state=42, max_iter=200)\n",
    "\n",
    "# # Fit the model on training data\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Now you can predict on test data, for example:\n",
    "# y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05be6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# def objective(trial):\n",
    "#     penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "#     solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs', 'newton-cg'])\n",
    "    \n",
    "#     if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "#         raise optuna.TrialPruned()\n",
    "#     if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs', 'newton-cg']:\n",
    "#         raise optuna.TrialPruned()\n",
    "    \n",
    "#     C = trial.suggest_loguniform('C', 1e-3, 10)\n",
    "#     max_iter = trial.suggest_int('max_iter', 100, 300)\n",
    "#     class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "    \n",
    "#     model = LogisticRegression(\n",
    "#         penalty=penalty,\n",
    "#         C=C,\n",
    "#         solver=solver,\n",
    "#         max_iter=max_iter,\n",
    "#         class_weight=class_weight,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1,\n",
    "#     )\n",
    "    \n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predict probabilities on test set (for all classes)\n",
    "#     y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "#     # Calculate log loss (lower is better)\n",
    "#     loss = log_loss(y_test, y_proba)\n",
    "    \n",
    "#     # Return negative loss because Optuna maximizes the objective\n",
    "#     return -loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d99d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, f1_score, classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Identify the minority class from the training data\n",
    "from collections import Counter\n",
    "minority_class = min(Counter(y_train), key=Counter(y_train).get)\n",
    "\n",
    "def objective(trial):\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear', 'saga', 'lbfgs', 'newton-cg'])\n",
    "\n",
    "    if penalty == 'l1' and solver not in ['liblinear', 'saga']:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "    if penalty == 'l2' and solver not in ['liblinear', 'saga', 'lbfgs', 'newton-cg']:\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    C = trial.suggest_float('C', 1e-3, 10, log=True)\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 300)\n",
    "    class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        max_iter=max_iter,\n",
    "        class_weight=class_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Step 2: Compute recall and f1 for minority class only\n",
    "    recall_min = recall_score(y_test, y_pred, pos_label=minority_class)\n",
    "    f1_min = f1_score(y_test, y_pred, pos_label=minority_class)\n",
    "\n",
    "    # Step 3: Return a combination (you can tweak this)\n",
    "    return recall_min + 0.5 * f1_min  # prioritizing recall more, but not ignoring F1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4cb8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:35:07,006] A new study created in memory with name: no-name-617b68d1-f3bf-46ae-9be0-36766bbdb4b8\n",
      "[I 2025-07-26 00:35:09,784] Trial 0 finished with value: 0.9748581761969346 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.16224449702505372, 'max_iter': 226, 'class_weight': 'balanced'}. Best is trial 0 with value: 0.9748581761969346.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:10,442] Trial 1 finished with value: 0.9760015529834267 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.4370958337481687, 'max_iter': 282, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.9760015529834267.\n",
      "[I 2025-07-26 00:35:10,444] Trial 2 pruned. \n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:15,953] Trial 3 finished with value: 0.26077091001800595 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.31069921083006546, 'max_iter': 197, 'class_weight': None}. Best is trial 1 with value: 0.9760015529834267.\n",
      "[I 2025-07-26 00:35:15,953] Trial 4 pruned. \n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:16,545] Trial 5 finished with value: 0.2588988394553262 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.10052210022881237, 'max_iter': 299, 'class_weight': None}. Best is trial 1 with value: 0.9760015529834267.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:17,082] Trial 6 finished with value: 0.23930239004475448 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.03473422557618869, 'max_iter': 197, 'class_weight': None}. Best is trial 1 with value: 0.9760015529834267.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:17,626] Trial 7 finished with value: 0.12168977430789249 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.0028718523817253643, 'max_iter': 162, 'class_weight': None}. Best is trial 1 with value: 0.9760015529834267.\n",
      "[I 2025-07-26 00:35:17,628] Trial 8 pruned. \n",
      "[I 2025-07-26 00:35:20,009] Trial 9 finished with value: 0.26993494973388527 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 4.149131105660303, 'max_iter': 286, 'class_weight': None}. Best is trial 1 with value: 0.9760015529834267.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:22,405] Trial 10 finished with value: 0.9717914194629999 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 3.110074881793042, 'max_iter': 100, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.9760015529834267.\n",
      "[I 2025-07-26 00:35:23,993] Trial 11 finished with value: 0.9755015654790016 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.4937984218006645, 'max_iter': 251, 'class_weight': 'balanced'}. Best is trial 1 with value: 0.9760015529834267.\n",
      "[I 2025-07-26 00:35:25,664] Trial 12 finished with value: 0.9762525289628191 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.7975351067260641, 'max_iter': 259, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:27,271] Trial 13 finished with value: 0.9762525289628191 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.160474796221049, 'max_iter': 264, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:28,825] Trial 14 finished with value: 0.9762166395109444 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 9.703032079599712, 'max_iter': 246, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:30,521] Trial 15 finished with value: 0.9762525289628191 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.3555225180044408, 'max_iter': 254, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:32,050] Trial 16 finished with value: 0.9739280371471314 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.022832900073227906, 'max_iter': 222, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:33,657] Trial 17 finished with value: 0.9762525289628191 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.0685630106264101, 'max_iter': 166, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:33,660] Trial 18 pruned. \n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:40,054] Trial 19 finished with value: 0.9743570791854962 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.03136614571999363, 'max_iter': 265, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:41,644] Trial 20 finished with value: 0.9669529777816732 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.001047764173721939, 'max_iter': 224, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:43,225] Trial 21 finished with value: 0.9762525289628191 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.4327817655347206, 'max_iter': 270, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:44,852] Trial 22 finished with value: 0.9762525289628191 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 1.3558558225305564, 'max_iter': 251, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:45,441] Trial 23 finished with value: 0.9762166395109444 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 3.016334416177834, 'max_iter': 239, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:46,068] Trial 24 finished with value: 0.9762525289628191 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 0.9627513357407097, 'max_iter': 268, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:46,730] Trial 25 finished with value: 0.9762166395109444 and parameters: {'penalty': 'l2', 'solver': 'newton-cg', 'C': 7.518953219710504, 'max_iter': 298, 'class_weight': 'balanced'}. Best is trial 12 with value: 0.9762525289628191.\n",
      "[I 2025-07-26 00:35:46,734] Trial 26 pruned. \n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:51,670] Trial 27 finished with value: 0.976609060108113 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.2144364237310639, 'max_iter': 218, 'class_weight': 'balanced'}. Best is trial 27 with value: 0.976609060108113.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:55,814] Trial 28 finished with value: 0.9766448581085538 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.24622546239324064, 'max_iter': 177, 'class_weight': 'balanced'}. Best is trial 28 with value: 0.9766448581085538.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:35:59,786] Trial 29 finished with value: 0.9747509608596753 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.15073453587092855, 'max_iter': 160, 'class_weight': 'balanced'}. Best is trial 28 with value: 0.9766448581085538.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:03,261] Trial 30 finished with value: 0.9722867963954551 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.05635498453615817, 'max_iter': 142, 'class_weight': 'balanced'}. Best is trial 28 with value: 0.9766448581085538.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:08,284] Trial 31 finished with value: 0.9765732739809723 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.26007751081523856, 'max_iter': 211, 'class_weight': 'balanced'}. Best is trial 28 with value: 0.9766448581085538.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:12,313] Trial 32 finished with value: 0.9766448581085538 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.18669556040596777, 'max_iter': 179, 'class_weight': 'balanced'}. Best is trial 28 with value: 0.9766448581085538.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:16,922] Trial 33 finished with value: 0.9766806679882052 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.19674387572078844, 'max_iter': 180, 'class_weight': 'balanced'}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:21,296] Trial 34 finished with value: 0.9765732739809723 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.06963818702539702, 'max_iter': 182, 'class_weight': 'balanced'}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:26,399] Trial 35 finished with value: 0.9762874116947442 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.011369042266175031, 'max_iter': 183, 'class_weight': 'balanced'}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:31,070] Trial 36 finished with value: 0.9721804511278196 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.17039267474971867, 'max_iter': 142, 'class_weight': 'balanced'}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:35,864] Trial 37 finished with value: 0.9766806679882052 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.19936032789163546, 'max_iter': 180, 'class_weight': 'balanced'}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:40,281] Trial 38 finished with value: 0.25874443036259437 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.43589376910935124, 'max_iter': 183, 'class_weight': None}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:44,072] Trial 39 finished with value: 0.9713241540473229 and parameters: {'penalty': 'l1', 'solver': 'saga', 'C': 0.1047161221076884, 'max_iter': 138, 'class_weight': 'balanced'}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:49,078] Trial 40 finished with value: 0.2597319820896474 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.35475620674432423, 'max_iter': 203, 'class_weight': None}. Best is trial 33 with value: 0.9766806679882052.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:53,546] Trial 41 finished with value: 0.9773239067818801 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.226940840627687, 'max_iter': 176, 'class_weight': 'balanced'}. Best is trial 41 with value: 0.9773239067818801.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:36:57,634] Trial 42 finished with value: 0.9765732739809723 and parameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.13170538405513388, 'max_iter': 170, 'class_weight': 'balanced'}. Best is trial 41 with value: 0.9773239067818801.\n",
      "[I 2025-07-26 00:36:58,345] Trial 43 finished with value: 0.9771113022774867 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.06721941312688373, 'max_iter': 153, 'class_weight': 'balanced'}. Best is trial 41 with value: 0.9773239067818801.\n",
      "[I 2025-07-26 00:36:59,138] Trial 44 finished with value: 0.269058484795848 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.05308845031021141, 'max_iter': 155, 'class_weight': None}. Best is trial 41 with value: 0.9773239067818801.\n",
      "[I 2025-07-26 00:36:59,790] Trial 45 finished with value: 0.9710865424478107 and parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 0.017728452135766692, 'max_iter': 122, 'class_weight': 'balanced'}. Best is trial 41 with value: 0.9773239067818801.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:37:00,427] Trial 46 finished with value: 0.9768598957817437 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.6277565793035794, 'max_iter': 195, 'class_weight': 'balanced'}. Best is trial 41 with value: 0.9773239067818801.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:37:02,538] Trial 47 finished with value: 0.27369835880022636 and parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 0.6174470446417791, 'max_iter': 196, 'class_weight': None}. Best is trial 41 with value: 0.9773239067818801.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:37:03,167] Trial 48 finished with value: 0.9770735435574194 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.10245107145770754, 'max_iter': 191, 'class_weight': 'balanced'}. Best is trial 41 with value: 0.9773239067818801.\n",
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  warnings.warn(\n",
      "[I 2025-07-26 00:37:03,818] Trial 49 finished with value: 0.9770021178131618 and parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 0.09694840967271276, 'max_iter': 197, 'class_weight': 'balanced'}. Best is trial 41 with value: 0.9773239067818801.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'penalty': 'l2', 'solver': 'saga', 'C': 0.226940840627687, 'max_iter': 176, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# Run Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de062261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7298959318826869\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.72      0.82     10974\n",
      "         1.0       0.30      0.76      0.43      1710\n",
      "\n",
      "    accuracy                           0.73     12684\n",
      "   macro avg       0.63      0.74      0.63     12684\n",
      "weighted avg       0.86      0.73      0.77     12684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Retrain with best model\n",
    "best_model = LogisticRegression(**best_params, random_state=42, n_jobs=-1)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Final predictions and evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58ca7384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model update inserted successfully with classification metrics.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Sample values (replace with dynamic evaluation if needed)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "loss = log_loss(y_test, y_pred)\n",
    "\n",
    "# Model serialization\n",
    "model_blob = pickle.dumps(best_model)\n",
    "\n",
    "# Classification report as a dictionary\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Extract metrics\n",
    "macro_f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "recall_minority = report[\"1.0\"][\"recall\"]\n",
    "f1_minority = report[\"1.0\"][\"f1-score\"]\n",
    "f1_majority = report[\"0.0\"][\"f1-score\"]\n",
    "\n",
    "\n",
    "fit_status = \"good\"\n",
    "\n",
    "# DB Insert Details\n",
    "model_id = 1\n",
    "client_id = \"1\"\n",
    "round_num = 2\n",
    "\n",
    "# DB Connection\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"centralAuth\",\n",
    "    password=\"messi10\",\n",
    "    database=\"fl_database\"\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Updated insert query\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO client_updates \n",
    "(model_id, client_id, model_blob, accuracy, loss, round_num, macro_f1, recall_minority, f1_minority, f1_majority, fit_status)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Execute Insert\n",
    "cursor.execute(insert_query, (\n",
    "    model_id, client_id, model_blob, accuracy, loss, round_num,\n",
    "    macro_f1, recall_minority, f1_minority, f1_majority, fit_status\n",
    "))\n",
    "conn.commit()\n",
    "\n",
    "print(\" Model update inserted successfully with classification metrics.\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
